{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd011f1",
   "metadata": {},
   "source": [
    "# Roteiro Completo de Aprendizado de Máquina com Dados Tabulares (Heart Dataset)\n",
    "\n",
    "\n",
    "O notebook apresenta um **pipeline completo de Machine Learning**, cobrindo desde a análise inicial dos dados até a avaliação final de modelos de **classificação** e **regressão**.\n",
    "\n",
    "\n",
    "### Objetivos principais:\n",
    "- Compreender a estrutura do conjunto de dados\n",
    "- Preparar os dados corretamente para modelagem\n",
    "- Treinar e comparar **vários modelos de Machine Learning**\n",
    "- Avaliar os modelos com métricas adequadas\n",
    "- Aplicar técnicas de **explicabilidade (feature importance)**\n",
    "\n",
    "\n",
    "### Tarefas abordadas:\n",
    "- ✔ Classificação (prever presença de doença cardíaca)\n",
    "- ✔ Regressão (prever um valor contínuo a partir das features)\n",
    "\n",
    "\n",
    "O notebook foi estruturado de forma **didática**, seguindo boas práticas utilizadas em projetos reais de Ciência de Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# Modelos de classificação\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Modelos de regressão\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f3e4c",
   "metadata": {},
   "source": [
    "## 1) Carregar e inspecionar os dados\n",
    "\n",
    "\n",
    "Antes de qualquer modelagem, é essencial entender os dados disponíveis.\n",
    "\n",
    "\n",
    "Nesta etapa temos:\n",
    "- Carregar o conjunto de dados\n",
    "- Visualizar as primeiras linhas\n",
    "- Verificar o número de amostras (linhas) e atributos (colunas)\n",
    "\n",
    "\n",
    "Isso ajuda a identificar possíveis problemas iniciais, como:\n",
    "- Dados faltantes\n",
    "- Tipos incorretos de variáveis\n",
    "- Colunas que precisarão de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bba57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heart.csv')\n",
    "display(df.head())\n",
    "print('Shape:', df.shape)\n",
    "print('\\nTipos de coluna:')\n",
    "display(df.dtypes)\n",
    "\n",
    "print('\\nValores faltantes por coluna:')\n",
    "display(df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "print('\\nDistribuição do alvo (target):')\n",
    "display(df['target'].value_counts())\n",
    "display(df['target'].value_counts(normalize=True).rename('proporção'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d542a4",
   "metadata": {},
   "source": [
    "## 2) Separar X (features) e y (alvo)\n",
    "\n",
    "\n",
    "Em problemas de **aprendizado supervisionado**, separamos:\n",
    "- **X** → variáveis explicativas (features)\n",
    "- **y** → variável alvo (o que queremos prever)\n",
    "\n",
    "\n",
    "Neste caso:\n",
    "- O alvo é a coluna `target`\n",
    "- O problema é de **classificação binária**:\n",
    "- `0` → ausência de doença cardíaca\n",
    "- `1` → presença de doença cardíaca\n",
    "\n",
    "\n",
    "Essa separação é fundamental para treinar corretamente os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b19b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "print('X:', X.shape, 'y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef18ab4",
   "metadata": {},
   "source": [
    "## 3) Dividir os dados em treino e teste\n",
    "\n",
    "\n",
    "Para avaliar se o modelo generaliza bem para dados novos, dividimos o conjunto em:\n",
    "- **Treino**: usado para ajustar o modelo\n",
    "- **Teste**: usado apenas para avaliação final\n",
    "\n",
    "\n",
    "Boas práticas adotadas aqui:\n",
    "- Uso de `test_size` para controlar o tamanho do conjunto de teste\n",
    "- Uso de `random_state` para reprodutibilidade\n",
    "- Uso de `stratify=y` para manter a proporção das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "print('Treino:', X_train.shape, 'Teste:', X_test.shape)\n",
    "print('Proporção classes no treino:')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "print('Proporção classes no teste:')\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775777b",
   "metadata": {},
   "source": [
    "## 4) Pré-processamento dos dados\n",
    "\n",
    "Dados reais quase nunca estão prontos para serem utilizados diretamente por modelos\n",
    "de Machine Learning. Por isso, nesta etapa construímos um **pipeline completo de\n",
    "pré-processamento**, garantindo que cada tipo de variável receba o tratamento adequado.\n",
    "\n",
    "### Estratégia adotada\n",
    "\n",
    "As variáveis foram **explicitamente separadas** em dois grupos:\n",
    "- **Numéricas**: variáveis contínuas ou ordinais\n",
    "- **Categóricas**: variáveis discretas que representam categorias\n",
    "\n",
    "Essa separação manual é especialmente importante neste dataset, pois algumas variáveis\n",
    "são representadas por números, mas possuem **natureza categórica** (ex.: `sex`, `cp`, `thal`).\n",
    "\n",
    "### Tratamento das variáveis numéricas\n",
    "Para as variáveis numéricas, aplicamos:\n",
    "- **Imputação de valores faltantes** usando a mediana\n",
    "- **Padronização (StandardScaler)** para colocar todas na mesma escala\n",
    "\n",
    "### Tratamento das variáveis categóricas\n",
    "Para as variáveis categóricas, aplicamos:\n",
    "- **Imputação de valores faltantes** usando a moda\n",
    "- **One-Hot Encoding**, permitindo que modelos matemáticos lidem corretamente com categorias\n",
    "- Uso de `handle_unknown='ignore'` para evitar erros com categorias não vistas no treino\n",
    "\n",
    "### Integração com ColumnTransformer\n",
    "Utilizamos o **ColumnTransformer** para:\n",
    "- Aplicar automaticamente o pipeline correto a cada tipo de variável\n",
    "- Garantir que o pré-processamento seja executado corretamente dentro da validação cruzada\n",
    "- Descartar colunas não listadas (`remainder='drop'`), evitando comportamentos inesperados\n",
    "\n",
    "### Vantagens dessa abordagem\n",
    "- Evita **vazamento de dados (data leakage)**\n",
    "- Garante consistência entre treino, validação e teste\n",
    "- Facilita o uso de **Grid Search** e **Cross-Validation**\n",
    "- Deixa o código mais organizado, modular e reutilizável\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = [c for c in X_train.columns if c not in numeric_features]\n",
    "\n",
    "# 1) Definição MANUAL (mais correta para esse dataset)\n",
    "cat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "num_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# 2) Pipelines de tratamento\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3) Junta tudo (cada tipo recebe o tratamento correto)\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe, num_cols),\n",
    "        ('cat', cat_pipe, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'  # descarta qualquer coluna não listada (evita surpresa)\n",
    ")\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = preprocess.fit_transform(X_train)\n",
    "print(X_train_pp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3fdb4",
   "metadata": {},
   "source": [
    "## 5) Definição e comparação dos modelos de classificação\n",
    "\n",
    "Nesta etapa definimos e comparamos **múltiplos algoritmos de classificação** utilizando\n",
    "uma abordagem **padronizada e justa**, baseada em validação cruzada e otimização de\n",
    "hiperparâmetros.\n",
    "\n",
    "Em vez de treinar cada modelo manualmente, usamos uma **função genérica**\n",
    "que aplica exatamente o mesmo pipeline de pré-processamento, validação e avaliação\n",
    "para todos os algoritmos.\n",
    "\n",
    "### Modelos avaliados\n",
    "Os seguintes modelos de classificação são testados:\n",
    "- **Regressão Logística** – modelo linear e interpretável\n",
    "- **KNN (K-Nearest Neighbors)** – modelo baseado em proximidade entre amostras\n",
    "- **SVM (Support Vector Machine)** – modelo de margem máxima\n",
    "- **Árvore de Decisão** – modelo não linear e interpretável\n",
    "- **Random Forest** – conjunto de árvores (ensemble)\n",
    "- **Gradient Boosting** – ensemble sequencial focado em reduzir erros\n",
    "\n",
    "Essa diversidade permite comparar modelos:\n",
    "- Lineares vs. não lineares  \n",
    "- Simples vs. ensembles  \n",
    "- Baseados em distância, margens ou árvores  \n",
    "\n",
    "### Estratégia de avaliação\n",
    "Para garantir uma comparação justa entre os modelos, adotamos:\n",
    "\n",
    "- **StratifiedKFold (k=5)**  \n",
    "  Mantém a proporção das classes em cada dobra da validação cruzada.\n",
    "\n",
    "- **Pipeline (pré-processamento + modelo)**  \n",
    "  Garante que todo o pré-processamento seja aplicado corretamente dentro da validação,\n",
    "  evitando vazamento de dados (*data leakage*).\n",
    "\n",
    "- **GridSearchCV**  \n",
    "  Testa automaticamente diferentes combinações de hiperparâmetros para cada modelo.\n",
    "\n",
    "- **Múltiplas métricas de avaliação**  \n",
    "  Avaliamos simultaneamente:\n",
    "  - accuracy\n",
    "  - precision\n",
    "  - recall\n",
    "  - f1\n",
    "\n",
    "### Critério de seleção do melhor modelo\n",
    "Embora várias métricas sejam calculadas, o melhor modelo é escolhido com base no\n",
    "**F1-score** (`refit='f1'`), pois essa métrica equilibra *precision* e *recall* e é\n",
    "mais robusta quando há desbalanceamento ou custos diferentes entre erros.\n",
    "\n",
    "### Organização dos resultados\n",
    "Para cada modelo testado, armazenamos:\n",
    "- Melhor F1 médio na validação cruzada\n",
    "- Melhores hiperparâmetros encontrados\n",
    "- Pipeline final treinado com esses hiperparâmetros\n",
    "- Resultados completos da validação cruzada\n",
    "\n",
    "Esses resultados são salvos em uma lista (`results_cls`) para posterior análise e comparação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "def run_grid(name, estimator, param_grid):\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess), ('model', estimator)])\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        refit='f1',  # escolhe o melhor pelo F1\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return {\n",
    "        'model_name': name,\n",
    "        'best_f1_cv': grid.best_score_,\n",
    "        'best_params': grid.best_params_,\n",
    "        'best_estimator': grid.best_estimator_,\n",
    "        'cv_results': grid.cv_results_\n",
    "    }\n",
    "\n",
    "results_cls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473861a",
   "metadata": {},
   "source": [
    "## 5.1) Espaço de busca de hiperparâmetros (Classificação)\n",
    "\n",
    "Após definir a estratégia de validação e avaliação, especificamos agora\n",
    "**quais modelos serão treinados** e **quais hiperparâmetros serão explorados**\n",
    "pelo GridSearchCV.\n",
    "\n",
    "Cada modelo é definido juntamente com um **conjunto de hiperparâmetros relevantes**,\n",
    "permitindo que o processo de validação cruzada encontre automaticamente a melhor\n",
    "configuração para cada algoritmo.\n",
    "\n",
    "A estrutura utilizada é uma lista de tuplas contendo:\n",
    "1. Nome do modelo (para identificação)\n",
    "2. Estimador do scikit-learn\n",
    "3. Grade de hiperparâmetros (`param_grid`)\n",
    "\n",
    "### Modelos e hiperparâmetros avaliados\n",
    "\n",
    "#### Regressão Logística\n",
    "- Modelo linear amplamente utilizado como baseline\n",
    "- `C`: controla a força da regularização\n",
    "- `penalty='l2'`: regularização padrão\n",
    "- `class_weight`: permite compensar possíveis desbalanceamentos de classe\n",
    "\n",
    "#### SVM com kernel RBF\n",
    "- Modelo não linear baseado em margens máximas\n",
    "- `C`: controla o trade-off entre margem larga e erro\n",
    "- `gamma`: define o alcance da influência de cada amostra\n",
    "- `class_weight`: ajuste para possíveis desbalanceamentos\n",
    "\n",
    "#### K-Nearest Neighbors (KNN)\n",
    "- Modelo baseado em distância entre amostras\n",
    "- `n_neighbors`: número de vizinhos considerados\n",
    "- `weights`: ponderação uniforme ou por distância\n",
    "- `p`: métrica de distância (Manhattan ou Euclidiana)\n",
    "\n",
    "#### Naive Bayes Gaussiano\n",
    "- Modelo probabilístico simples e rápido\n",
    "- Poucos hiperparâmetros ajustáveis\n",
    "- `var_smoothing`: melhora a estabilidade numérica\n",
    "\n",
    "#### Random Forest\n",
    "- Ensemble de árvores de decisão\n",
    "- `n_estimators`: número de árvores\n",
    "- `max_depth`: profundidade máxima das árvores\n",
    "- `min_samples_split`: mínimo de amostras para divisão\n",
    "- `class_weight`: tratamento de desbalanceamento\n",
    "\n",
    "#### Gradient Boosting\n",
    "- Ensemble sequencial focado em reduzir erros anteriores\n",
    "- `n_estimators`: número de árvores\n",
    "- `learning_rate`: taxa de aprendizado\n",
    "- `max_depth`: complexidade das árvores base\n",
    "\n",
    "### Observações importantes\n",
    "- Todos os hiperparâmetros usam o prefixo `model__` pois o estimador está\n",
    "  encapsulado em um **Pipeline**.\n",
    "- As grades foram mantidas **moderadas**, equilibrando qualidade do ajuste\n",
    "  e custo computacional.\n",
    "- Essa abordagem garante uma **comparação justa**, já que todos os modelos\n",
    "  passam pelo mesmo processo de pré-processamento, validação cruzada e seleção.\n",
    "\n",
    "Ao final, cada modelo será avaliado com base no **F1-score médio em validação cruzada**,\n",
    "permitindo escolher a abordagem mais adequada para o problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096459",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_grids = [\n",
    "    (\n",
    "        'LogisticRegression',\n",
    "        LogisticRegression(max_iter=5000, random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__C': [0.1, 1.0, 10.0],\n",
    "            'model__penalty': ['l2'],\n",
    "            'model__class_weight': [None, 'balanced'],\n",
    "            'model__solver': ['lbfgs']\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'SVC_RBF',\n",
    "        SVC(kernel='rbf', probability=False, random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__C': [0.5, 1.0, 5.0],\n",
    "            'model__gamma': ['scale', 0.1, 0.01],\n",
    "            'model__class_weight': [None, 'balanced']\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'KNN',\n",
    "        KNeighborsClassifier(),\n",
    "        {\n",
    "            'model__n_neighbors': [3, 5, 11, 21],\n",
    "            'model__weights': ['uniform', 'distance'],\n",
    "            'model__p': [1, 2]  # 1=Manhattan, 2=Euclidean\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'GaussianNB',\n",
    "        GaussianNB(),\n",
    "        {\n",
    "            # Não tem muitos hiperparâmetros; ainda assim testamos var_smoothing\n",
    "            'model__var_smoothing': [1e-09, 1e-08, 1e-07]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'RandomForest',\n",
    "        RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__n_estimators': [200, 500],\n",
    "            'model__max_depth': [None, 5, 10],\n",
    "            'model__min_samples_split': [2, 10],\n",
    "            'model__class_weight': [None, 'balanced']\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'GradientBoosting',\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__n_estimators': [100, 300],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__max_depth': [2, 3]\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "len(models_and_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a5527",
   "metadata": {},
   "source": [
    "## 5.2) Execução do Grid Search e comparação final dos modelos\n",
    "\n",
    "Nesta etapa executamos efetivamente o **GridSearchCV para todos os modelos definidos**,\n",
    "utilizando a mesma estratégia de pré-processamento, validação cruzada e avaliação.\n",
    "\n",
    "Cada modelo é treinado e avaliado de forma **independente**, mas seguindo exatamente\n",
    "o mesmo protocolo, garantindo uma comparação justa.\n",
    "\n",
    "### Execução dos experimentos\n",
    "Para cada modelo presente em `models_and_grids`:\n",
    "- Aplicamos o pipeline completo (pré-processamento + modelo)\n",
    "- Executamos o Grid Search com validação cruzada estratificada\n",
    "- Selecionamos automaticamente a melhor configuração com base no **F1-score**\n",
    "- Armazenamos os resultados relevantes em uma lista (`results_cls`)\n",
    "\n",
    "Esse processo pode levar alguns minutos, pois envolve múltiplos treinos por modelo.\n",
    "\n",
    "### Organização dos resultados\n",
    "Após a execução de todos os experimentos, consolidamos os resultados em uma tabela\n",
    "resumo contendo:\n",
    "- Nome do modelo\n",
    "- Melhor **F1-score médio** obtido na validação cruzada\n",
    "- Conjunto de **hiperparâmetros ótimos** encontrados pelo Grid Search\n",
    "\n",
    "A tabela é então **ordenada do maior para o menor F1-score**, facilitando a identificação\n",
    "do modelo com melhor desempenho médio durante a validação cruzada.\n",
    "\n",
    "### Interpretação\n",
    "O modelo no topo da tabela representa aquele que, em média:\n",
    "- Obteve o melhor equilíbrio entre *precision* e *recall*\n",
    "- Apresentou maior robustez ao longo das dobras da validação cruzada\n",
    "\n",
    "Esse modelo será utilizado nas próximas etapas para:\n",
    "- Avaliação final no conjunto de teste\n",
    "- Análises adicionais, como matriz de confusão e explicabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model, grid in models_and_grids:\n",
    "    print(f'Rodando: {name} ...')\n",
    "    res = run_grid(name, model, grid)\n",
    "    results_cls.append(res)\n",
    "print('Concluído!')\n",
    "\n",
    "# Tabela resumo (ordenada pelo melhor F1 médio na validação cruzada)\n",
    "summary_cls = pd.DataFrame([\n",
    "    {\n",
    "        'modelo': r['model_name'],\n",
    "        'f1_cv': r['best_f1_cv'],\n",
    "        'melhores_hiperparametros': r['best_params']\n",
    "    }\n",
    "    for r in results_cls\n",
    "]).sort_values('f1_cv', ascending=False)\n",
    "\n",
    "display(summary_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde40b6e",
   "metadata": {},
   "source": [
    "## 6) Seleção do melhor modelo e avaliação final no conjunto de teste\n",
    "\n",
    "Após a execução do Grid Search e da validação cruzada, selecionamos agora\n",
    "o **melhor modelo de classificação**, com base no **F1-score médio** obtido\n",
    "durante a validação cruzada.\n",
    "\n",
    "Essa etapa simula um cenário real de uso, avaliando o desempenho do modelo\n",
    "em **dados nunca vistos durante o treinamento**.\n",
    "\n",
    "### Seleção do melhor modelo\n",
    "- Identificamos o modelo com maior F1 médio na validação cruzada\n",
    "- Recuperamos o **pipeline completo** (pré-processamento + modelo)\n",
    "  já treinado com os melhores hiperparâmetros\n",
    "- Não é necessário re-treinar manualmente, pois o `GridSearchCV`\n",
    "  já devolve o `best_estimator_` ajustado\n",
    "\n",
    "### Avaliação no conjunto de teste\n",
    "O modelo selecionado é avaliado no conjunto de teste usando as seguintes métricas:\n",
    "\n",
    "- **Accuracy**: proporção total de acertos\n",
    "- **Precision**: qualidade das previsões positivas\n",
    "- **Recall**: capacidade de detectar a classe positiva\n",
    "- **F1-score**: equilíbrio entre precision e recall\n",
    "\n",
    "Além disso, apresentamos:\n",
    "- **Classification Report**, com métricas por classe\n",
    "- **Matriz de confusão**, para visualizar erros e acertos do modelo\n",
    "\n",
    "### Interpretação\n",
    "Essa avaliação final é a estimativa mais próxima do desempenho real do modelo\n",
    "em produção, pois utiliza dados que **não participaram nem do treinamento\n",
    "nem da validação cruzada**.\n",
    "\n",
    "Os resultados obtidos aqui são usados como base para:\n",
    "- Comparação com outros modelos\n",
    "- Discussões sobre desempenho e limitações\n",
    "- Etapas posteriores de explicabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = summary_cls.iloc[0]\n",
    "best_model_name = best_row['modelo']\n",
    "best_entry = next(r for r in results_cls if r['model_name'] == best_model_name)\n",
    "best_pipe = best_entry['best_estimator']\n",
    "\n",
    "print('Melhor modelo (por F1-CV):', best_model_name)\n",
    "print('Melhores hiperparâmetros:')\n",
    "display(best_entry['best_params'])\n",
    "\n",
    "# Treina no treino completo (GridSearchCV já devolve o best_estimator treinado)\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'ACC={acc:.3f} | PREC={prec:.3f} | REC={rec:.3f} | F1={f1:.3f}')\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(f'Matriz de Confusão - {best_model_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51067b9b",
   "metadata": {},
   "source": [
    "## 7) Bônus: Explicabilidade – Importância das variáveis\n",
    "\n",
    "Além do desempenho preditivo, é fundamental entender **como o modelo toma decisões**.\n",
    "Nesta etapa aplicamos uma técnica de explicabilidade baseada em **Permutation Importance**,\n",
    "adequada para dados tabulares e compatível com qualquer tipo de modelo.\n",
    "\n",
    "### Intuição do método\n",
    "A ideia é simples:\n",
    "- Embaralhamos os valores de uma variável, quebrando sua relação com o alvo\n",
    "- Medimos o quanto a métrica de interesse (F1-score) piora\n",
    "- Quanto maior a queda, mais importante é a variável para o modelo\n",
    "\n",
    "### Por que usar Permutation Importance?\n",
    "- Método **agnóstico ao modelo**\n",
    "- Mede impacto direto na **métrica final**\n",
    "- Pode ser aplicado em dados de teste, evitando viés otimista\n",
    "- Fácil de interpretar e comunicar\n",
    "\n",
    "### Interpretação\n",
    "As variáveis com maior queda média no F1 são aquelas que mais influenciam\n",
    "as decisões do modelo. Variáveis com impacto próximo de zero têm pouca\n",
    "ou nenhuma contribuição preditiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33187d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "perm = permutation_importance(\n",
    "    best_pipe,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "importances = pd.Series(perm.importances_mean, index=X_test.columns).sort_values(ascending=False)\n",
    "\n",
    "display(importances.head(15))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "importances.head(15).sort_values().plot(kind='barh')\n",
    "plt.title('Top 15 Importâncias (Permutation Importance)')\n",
    "plt.xlabel('Queda média no F1 quando embaralha a feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b358fa",
   "metadata": {},
   "source": [
    "# Parte 2: Regressão (≥ 3 modelos)\n",
    "Agora faremos um problema de regressão **usando o mesmo dataset**, apenas escolhendo um alvo contínuo.\n",
    "\n",
    "### Qual variável vamos prever?\n",
    "Vamos prever `chol` (colesterol), que é numérica.\n",
    "\n",
    "**Por quê isso faz sentido?**\n",
    "- Você treina o pipeline de regressão exigido pelo enunciado.\n",
    "- Reaproveita o mesmo conjunto tabular.\n",
    "\n",
    "### Métricas exigidas\n",
    "- **R²**: quanto da variância do alvo o modelo explica.\n",
    "- **RMSE**: erro médio quadrático na escala original (quanto menor, melhor).\n",
    "\n",
    "Vamos comparar 3 modelos:\n",
    "- Ridge (linear com regularização)\n",
    "- RandomForestRegressor\n",
    "- GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a337e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg = df['chol']\n",
    "X_reg = df.drop(columns=['chol', 'target'])  # remove colesterol e o alvo de classificação\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('X_reg:', X_reg.shape, 'y_reg:', y_reg.shape)\n",
    "print('Treino:', Xr_train.shape, 'Teste:', Xr_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f34e7",
   "metadata": {},
   "source": [
    "## 8) Pipeline de regressão e validação cruzada\n",
    "\n",
    "Nesta etapa repetimos a mesma lógica adotada na classificação, agora aplicada\n",
    "a um **problema de regressão**, no qual o objetivo é prever uma variável contínua.\n",
    "\n",
    "Embora o fluxo geral seja semelhante, há diferenças importantes em relação:\n",
    "- Às métricas utilizadas\n",
    "- Ao critério de seleção do melhor modelo\n",
    "- À interpretação dos resultados\n",
    "\n",
    "### Pré-processamento dos dados\n",
    "O pré-processamento segue a mesma estratégia da classificação:\n",
    "- Variáveis numéricas:\n",
    "  - Imputação de valores faltantes pela mediana\n",
    "  - Padronização com `StandardScaler`\n",
    "- Variáveis categóricas:\n",
    "  - Imputação pela moda\n",
    "  - Codificação com `OneHotEncoder`\n",
    "- Uso de `ColumnTransformer` para aplicar cada tratamento corretamente\n",
    "- Descarte de colunas não listadas (`remainder='drop'`)\n",
    "\n",
    "Essa abordagem garante consistência e evita vazamento de dados durante a validação cruzada.\n",
    "\n",
    "### Validação cruzada e otimização de hiperparâmetros\n",
    "Utilizamos novamente o **GridSearchCV**, agora com foco em métricas de regressão.\n",
    "\n",
    "As métricas avaliadas são:\n",
    "- **RMSE (Root Mean Squared Error)**  \n",
    "  Mede o erro médio do modelo, penalizando erros grandes\n",
    "- **R² (coeficiente de determinação)**  \n",
    "  Mede o quanto da variância do alvo é explicada pelo modelo\n",
    "\n",
    "### Por que usar `neg_root_mean_squared_error`?\n",
    "O scikit-learn sempre assume que **métricas maiores são melhores**.\n",
    "Como o RMSE é um erro (quanto menor, melhor), o sklearn utiliza o valor negativo\n",
    "do RMSE durante a otimização.\n",
    "\n",
    "Por isso:\n",
    "- Usamos `neg_root_mean_squared_error` no `scoring`\n",
    "- Definimos `refit='rmse'` para escolher o modelo com menor erro\n",
    "- Convertimos o valor negativo para RMSE positivo apenas para interpretação\n",
    "\n",
    "### Organização dos resultados\n",
    "Para cada modelo de regressão testado, armazenamos:\n",
    "- Melhor RMSE médio na validação cruzada\n",
    "- Melhor R² médio\n",
    "- Melhores hiperparâmetros encontrados\n",
    "- Pipeline final treinado com esses hiperparâmetros\n",
    "- Resultados completos da validação cruzada\n",
    "\n",
    "Esses resultados são armazenados em uma lista (`results_reg`) para posterior\n",
    "comparação e análise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_reg = Xr_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features_reg = [c for c in Xr_train.columns if c not in numeric_features_reg]\n",
    "\n",
    "numeric_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocess_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_reg, numeric_features_reg),\n",
    "        ('cat', categorical_transformer_reg, categorical_features_reg)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "cv_reg = 5\n",
    "scoring_reg = {\n",
    "    'rmse': 'neg_root_mean_squared_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "def run_grid_reg(name, estimator, param_grid):\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_reg), ('model', estimator)])\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_reg,\n",
    "        scoring=scoring_reg,\n",
    "        refit='rmse',\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    grid.fit(Xr_train, yr_train)\n",
    "    return {\n",
    "        'model_name': name,\n",
    "        'best_neg_rmse_cv': grid.best_score_,\n",
    "        'best_rmse_cv': -grid.best_score_,\n",
    "        'best_params': grid.best_params_,\n",
    "        'best_estimator': grid.best_estimator_,\n",
    "        'cv_results': grid.cv_results_\n",
    "    }\n",
    "\n",
    "results_reg = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761af2a",
   "metadata": {},
   "source": [
    "### 8.1) Grades de hiperparâmetros dos modelos de regressão\n",
    "\n",
    "Assim como na classificação, não é adequado comparar modelos utilizando\n",
    "configurações arbitrárias ou padrões. Por isso, para cada algoritmo de\n",
    "regressão definimos uma **grade de hiperparâmetros plausíveis**, permitindo\n",
    "que o GridSearchCV encontre automaticamente a melhor configuração por\n",
    "validação cruzada.\n",
    "\n",
    "A escolha dos modelos contempla abordagens **lineares** e **não lineares**,\n",
    "permitindo avaliar diferentes níveis de complexidade e capacidade de ajuste.\n",
    "\n",
    "### Modelos avaliados\n",
    "\n",
    "#### Ridge Regression\n",
    "- Modelo linear com regularização L2\n",
    "- Útil como baseline robusto contra multicolinearidade\n",
    "- `alpha`: controla a força da regularização (valores maiores → modelo mais simples)\n",
    "\n",
    "#### Random Forest Regressor\n",
    "- Ensemble de árvores de decisão\n",
    "- Captura relações não lineares entre as variáveis\n",
    "- `n_estimators`: número de árvores no ensemble\n",
    "- `max_depth`: profundidade máxima das árvores\n",
    "- `min_samples_split`: mínimo de amostras para dividir um nó\n",
    "\n",
    "#### Gradient Boosting Regressor\n",
    "- Ensemble sequencial que corrige erros de modelos anteriores\n",
    "- Geralmente apresenta bom desempenho em dados tabulares\n",
    "- `n_estimators`: número de árvores\n",
    "- `learning_rate`: taxa de aprendizado\n",
    "- `max_depth`: complexidade das árvores base\n",
    "\n",
    "### Observações importantes\n",
    "- Todos os hiperparâmetros utilizam o prefixo `model__` pois os estimadores\n",
    "  estão encapsulados em um **Pipeline**.\n",
    "- As grades foram escolhidas para equilibrar **desempenho e custo computacional**.\n",
    "- Essa abordagem garante uma comparação justa entre modelos, pois todos são\n",
    "  avaliados sob a mesma estratégia de pré-processamento e validação cruzada.\n",
    "\n",
    "Ao final, cada modelo será comparado com base no **RMSE médio** obtido na\n",
    "validação cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_grids_reg = [\n",
    "    (\n",
    "        'Ridge',\n",
    "        Ridge(random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'RandomForestRegressor',\n",
    "        RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__n_estimators': [300, 800],\n",
    "            'model__max_depth': [None, 5, 10],\n",
    "            'model__min_samples_split': [2, 10]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        'GradientBoostingRegressor',\n",
    "        GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "        {\n",
    "            'model__n_estimators': [200, 500],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__max_depth': [2, 3]\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "len(models_and_grids_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f6e5a",
   "metadata": {},
   "source": [
    "### 8.2) Rodar GridSearchCV e consolidar resultados (Regressão)\n",
    "\n",
    "Nesta etapa executamos o **GridSearchCV** para cada modelo de regressão definido\n",
    "na lista `models_and_grids_reg`.\n",
    "\n",
    "Para cada algoritmo:\n",
    "- Rodamos a validação cruzada com a mesma estratégia de pré-processamento\n",
    "- Testamos as combinações de hiperparâmetros definidas na grade\n",
    "- Selecionamos automaticamente a melhor configuração com base no **RMSE**\n",
    "  (lembrando que o sklearn usa `neg_root_mean_squared_error` internamente)\n",
    "\n",
    "### O que armazenamos para cada modelo\n",
    "Após cada execução, salvamos em `results_reg`:\n",
    "- Melhor RMSE médio em validação cruzada (convertido para positivo para facilitar interpretação)\n",
    "- Melhores hiperparâmetros encontrados\n",
    "- Resultados completos (`cv_results_`) para análises posteriores\n",
    "\n",
    "### Tabela resumo (comparação final)\n",
    "Ao final, consolidamos tudo em um DataFrame (`summary_reg`) contendo:\n",
    "- `RMSE_cv`: erro médio (quanto menor, melhor)\n",
    "- `R2_medio_cv_para_melhor_rmse`: valor médio de R² correspondente **à mesma configuração**\n",
    "  que obteve o melhor RMSE\n",
    "- `melhores_hiperparametros`: hiperparâmetros escolhidos pelo Grid Search\n",
    "\n",
    "A tabela é ordenada do menor para o maior RMSE, facilitando identificar o regressor\n",
    "com melhor desempenho médio na validação cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model, grid in models_and_grids_reg:\n",
    "    print(f'Rodando: {name} ...')\n",
    "    res = run_grid_reg(name, model, grid)\n",
    "    results_reg.append(res)\n",
    "print('Concluído!')\n",
    "\n",
    "summary_reg = pd.DataFrame([\n",
    "    {\n",
    "        'modelo': r['model_name'],\n",
    "        'RMSE_cv': r['best_rmse_cv'],\n",
    "        'R2_medio_cv_para_melhor_rmse': r['cv_results']['mean_test_r2'][np.argmax(r['cv_results']['mean_test_rmse'])] if 'mean_test_rmse' in r['cv_results'] else np.nan,\n",
    "        'melhores_hiperparametros': r['best_params']\n",
    "    }\n",
    "    for r in results_reg\n",
    "]).sort_values('RMSE_cv', ascending=True)\n",
    "\n",
    "display(summary_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4cacc5",
   "metadata": {},
   "source": [
    "## 9) Avaliar o melhor regressor no conjunto de teste (RMSE e R²)\n",
    "\n",
    "Depois de comparar os modelos de regressão via validação cruzada, selecionamos agora\n",
    "o **melhor regressor** com base no **RMSE médio em CV** (quanto menor, melhor).\n",
    "\n",
    "Em seguida, fazemos a avaliação final no **conjunto de teste**, que contém dados\n",
    "que não participaram nem do treinamento nem da validação cruzada. Essa é a estimativa\n",
    "mais realista de como o modelo deve se comportar em novos dados.\n",
    "\n",
    "### Passos desta etapa\n",
    "1. Identificar o modelo com menor `RMSE_cv` na tabela `summary_reg`\n",
    "2. Recuperar o `best_estimator` (pipeline completo com pré-processamento + modelo)\n",
    "3. Gerar previsões no conjunto de teste (`Xr_test`)\n",
    "4. Calcular métricas de regressão no teste:\n",
    "   - **RMSE (teste)**: erro médio em unidades da variável alvo (penaliza erros grandes)\n",
    "   - **R² (teste)**: fração da variância explicada pelo modelo (quanto maior, melhor)\n",
    "\n",
    "### Visualização: Real vs Previsto\n",
    "Além das métricas, plotamos um gráfico de dispersão comparando:\n",
    "- eixo x: valores reais (`yr_test`)\n",
    "- eixo y: valores previstos (`yhat`)\n",
    "\n",
    "A linha diagonal representa o cenário ideal (**previsão perfeita**).\n",
    "Quanto mais os pontos estiverem próximos dessa linha, melhor o ajuste do modelo.\n",
    "\n",
    "> Observação: RMSE e R² devem ser interpretados juntos.  \n",
    "> Um RMSE baixo indica erro pequeno, enquanto um R² alto indica bom poder explicativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_row = summary_reg.iloc[0]\n",
    "best_reg_name = best_reg_row['modelo']\n",
    "best_reg_entry = next(r for r in results_reg if r['model_name'] == best_reg_name)\n",
    "best_reg_pipe = best_reg_entry['best_estimator']\n",
    "\n",
    "print('Melhor modelo (por RMSE-CV):', best_reg_name)\n",
    "print('Melhores hiperparâmetros:')\n",
    "display(best_reg_entry['best_params'])\n",
    "\n",
    "yhat = best_reg_pipe.predict(Xr_test)\n",
    "mse_test = mean_squared_error(yr_test, yhat)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(yr_test, yhat)\n",
    "\n",
    "print(f'RMSE (teste) = {rmse_test:.2f}')\n",
    "print(f'R² (teste)   = {r2_test:.3f}')\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(yr_test, yhat, alpha=0.6)\n",
    "plt.xlabel('Valor real (chol)')\n",
    "plt.ylabel('Valor previsto (chol)')\n",
    "plt.title(f'Regressão: Real vs Previsto - {best_reg_name}')\n",
    "plt.plot([yr_test.min(), yr_test.max()], [yr_test.min(), yr_test.max()])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80945b",
   "metadata": {},
   "source": [
    "## 10) BÔNUS: Explicabilidade na Regressão (Permutation Importance)\n",
    "\n",
    "Além de avaliar o desempenho do melhor regressor no teste, é útil entender\n",
    "**quais variáveis mais influenciam as previsões**.\n",
    "\n",
    "Nesta etapa usamos **Permutation Importance**, uma técnica de explicabilidade\n",
    "agnóstica ao modelo (funciona com regressão linear, árvores, ensembles etc.).\n",
    "\n",
    "### Como o método funciona\n",
    "A ideia é medir o impacto de cada feature na performance do modelo:\n",
    "- Embaralhamos os valores de uma feature (quebrando sua relação com o alvo)\n",
    "- Recalculamos a métrica no conjunto de teste\n",
    "- Observamos o quanto a métrica piora\n",
    "\n",
    "Como estamos em regressão, usamos **R²** como métrica:\n",
    "- Se embaralhar uma feature causa uma grande queda no **R²**, então ela é importante\n",
    "- Se a queda for próxima de zero, a feature contribui pouco para o modelo\n",
    "\n",
    "### Por que usar o conjunto de teste?\n",
    "Ao calcular a importância no **teste**, obtemos uma medida mais honesta do impacto\n",
    "das variáveis em dados não vistos, reduzindo o risco de interpretações otimistas.\n",
    "\n",
    "### Observação importante sobre os nomes das features\n",
    "Como o pipeline contém **One-Hot Encoding**, o conjunto final de features não é\n",
    "idêntico às colunas originais:\n",
    "- Uma variável categórica pode virar várias colunas binárias\n",
    "- Por isso usamos `get_feature_names_out()` para obter os nomes das features\n",
    "  **após o pré-processamento**\n",
    "\n",
    "### Resultado\n",
    "Por fim, exibimos e plotamos as **Top 15 features** com maior queda média no R²,\n",
    "facilitando a interpretação e discussão do que o modelo está usando para prever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_pipe.fit(Xr_train, yr_train)\n",
    "perm_reg = permutation_importance(\n",
    "    best_reg_pipe,\n",
    "    Xr_test,\n",
    "    yr_test,\n",
    "    n_repeats=20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "feature_names_reg = best_reg_pipe.named_steps['preprocess'].get_feature_names_out()\n",
    "importances_reg = pd.Series(perm_reg.importances_mean, index=feature_names_reg).sort_values(ascending=False)\n",
    "\n",
    "display(importances_reg.head(15))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "importances_reg.head(15).sort_values().plot(kind='barh')\n",
    "plt.title('Top 15 Importâncias (Permutation Importance) - Regressão')\n",
    "plt.xlabel('Queda média no R² quando embaralha a feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d935f3d",
   "metadata": {},
   "source": [
    "# Checklist do enunciado (para você conferir)\n",
    "### Classificação\n",
    "- [x] ≥ 5 modelos (usamos 6)\n",
    "- [x] Teste de hiperparâmetros em cada modelo (GridSearchCV)\n",
    "- [x] Validação cruzada (StratifiedKFold 5-fold)\n",
    "- [x] Métricas: matriz de confusão, acurácia, precisão, recall, F1\n",
    "- [x] Pipeline com tratamento de dados (imputação + escala)\n",
    "- [x] Atenção a desbalanceamento (uso de F1 e opção de class_weight)\n",
    "- [x] Indicação do modelo mais promissor e hiperparâmetros (impressos)\n",
    "\n",
    "### Regressão\n",
    "- [x] ≥ 3 modelos\n",
    "- [x] Teste de hiperparâmetros\n",
    "- [x] Validação cruzada\n",
    "- [x] Métricas: R² e RMSE\n",
    "- [x] Pipeline com imputação + escala\n",
    "\n",
    "### Bônus\n",
    "- [x] Explicabilidade via permutation importance (classificação e regressão)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
